{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/miniconda3/envs/multimodal/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/joseph/miniconda3/envs/multimodal/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision, os, PIL, pdb\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(tensor, num=25, wandb=0, name=''):\n",
    "    data = tensor.detach().cpu()\n",
    "    grid = make_grid(data[:num], nrow=5).permute(1,2,0)\n",
    "    \n",
    "    ## optional\n",
    "    if (wandb==1 and wandbact==1): # wandb : weights and biases (online tool)\n",
    "        wandb.log({name:wandb.Image(grid.numpy().clip(0,1))})\n",
    "    \n",
    "    plt.imshow(grid.clip(0,1)) # clip the values of the pixles to be inbetween 0~1\n",
    "    plt.show()\n",
    "    \n",
    "### hyperparameters and general parameters\n",
    "n_epochs = 10000\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "z_dim = 200\n",
    "device='cuda'\n",
    "\n",
    "cur_step = 0\n",
    "crit_cycles = 5 # 5 cycles of the critic -> 1 cycle of the generator training for advanced Wesserstein GAN\n",
    "gen_losses = []\n",
    "crit_losses = []\n",
    "show_step = 35\n",
    "save_step = 35 # will be checkpoint\n",
    "\n",
    "wandbact = 1 # to track stats through weights and biases, optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbellmake\u001b[0m (\u001b[33mbellmake-yonsei-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/joseph/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### optional\n",
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture   \n",
    "# capture all the output of the processes\n",
    "experiment_name = wandb.util.generate_id() # generate the name of this experiment\n",
    "\n",
    "myrun=wandb.init(# initialize experiment\n",
    "       project = \"wgan\",\n",
    "       group = experiment_name,\n",
    "       config = {\n",
    "           \"optimizer\":\"sgd\", # stochastic gradient descent\n",
    "           \"model\":\"wgan gp\", # Wesserstein GAN with Gradient Penalty,\n",
    "           \"epoch\":\"1000\",\n",
    "           \"batch_size\":128\n",
    "       }\n",
    ") \n",
    "\n",
    "config = wandb.Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru3n6hmj\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For nn.Conv2d: (reduce the size of the image for prediction : Discriminator)\n",
    "output_size = (n + 2 * pad - ks) // stride + 1 \n",
    "\n",
    "#### For nn.ConvTranspose2d: (grow from a value to full image for generation : Generator)\n",
    "output_size = (n - 1) * stride - 2 * padding + ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator model\n",
    "# ConvTranspose2d\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=64, d_dim=16):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim=z_dim\n",
    "        \n",
    "        self.gen = nn.Sequential(\n",
    "            ## ConvTranspose2d: in_channels, out_channels, kernel_size, stride=1, padding=0\n",
    "            ## Calculating new width and height: (n-1)*stride - 2*padding + ks\n",
    "            ## n = width or height\n",
    "            ## ks = kernel size\n",
    "            ## begin with a 1x1 image with z_dim number of channels (200)\n",
    "            nn.ConvTranspose2d(z_dim, d_dim*32, 4, 1, 0), # 1x1 -> 4x4 (ch: 200 -> 512)\n",
    "            nn.BatchNorm2d(d_dim*32),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(d_dim*32, d_dim*16, 4, 2, 1), # 8x8 (ch: 512 -> 256)\n",
    "            nn.BatchNorm2d(d_dim*16),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(d_dim*16, d_dim*8, 4, 2, 1), # 16x16 (ch: 256 -> 128)\n",
    "            nn.BatchNorm2d(d_dim*8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(d_dim*8, d_dim*4, 4, 2, 1), # 32x32 (ch: 128 -> 64)\n",
    "            nn.BatchNorm2d(d_dim*4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(d_dim*4, d_dim*2, 4, 2, 1), # 64x64 (ch: 64 -> 32)\n",
    "            nn.BatchNorm2d(d_dim*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(d_dim*2, 3, 4, 2, 1), # 128x128 (ch: 32 -> 3(RGB))\n",
    "            # we obtained final image, so no need for BatchNorm\n",
    "            nn.Tanh() # produce result in the range from -1 to 1 (suitable for image generation related GAN)\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x=noise.view(len(noise), self.z_dim, 1, 1)  # 128 (batch size) x 200 (channels : dim of the latent space) x 1 x 1 (one pixel)\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "def gen_noise(num, z_dim, device='cuda'):\n",
    "    return torch.randn(num, z_dim, device=device) # 128 x 200 noise generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic model (Discriminator)\n",
    "# Conv2d\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, d_dim=16):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.crit = nn.Sequential(\n",
    "            nn.Conv2d(3, d_dim, 4, 2, 1), # 128x128 -> 64x64 (ch: 3(RGB) -> 16)\n",
    "            nn.InstanceNorm2d(d_dim), # normalizing : changing the range of values for stabilizing # for Critic, InstanceNorm works best by experience\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(d_dim, d_dim*2, 4, 2, 1), # 32x32 (ch: 16 -> 32)\n",
    "            nn.InstanceNorm2d(d_dim*2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(d_dim*2, d_dim*4, 4, 2, 1), # 16x16 (ch: 32 -> 64)\n",
    "            nn.InstanceNorm2d(d_dim*4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(d_dim*4, d_dim*8, 4, 2, 1), # 8x8 (ch: 64 -> 128)\n",
    "            nn.InstanceNorm2d(d_dim*8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(d_dim*8, d_dim*16, 4, 2, 1), # 4x4 (ch: 128 -> 256)\n",
    "            nn.InstanceNorm2d(d_dim*8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(d_dim*16, 1, 4, 1, 0), # 1x1 (ch: 256 -> 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        # image :128 x 3 x 128 x 128\n",
    "        crit_pred = self.crit(image) # 128 x 1 x 1 x 1\n",
    "        return crit_pred.view(len(crit_pred), -1) # 128 x 1 (128 predictions of fake/real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
